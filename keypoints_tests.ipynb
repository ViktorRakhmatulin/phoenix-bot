{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600a4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dt_apriltags as apriltag\n",
    "import cv2\n",
    "import annotation_utils as utils\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import urx\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "dist = np.array([[-0.04797802,  0.04744357,  0.00017416,  0.00067967, -0.00408397]])\n",
    "mtx = np.array([[633.09029639, 0., 629.06462963], [0., 638.7544391, 362.74013262], [0., 0., 1.]])\n",
    "\n",
    "camera_params = [635.0, 635.0, 629.0646296262861, 362.7401326185789]\n",
    "corners_3D = np.array(\n",
    "[(0, 0,0),\n",
    " (24, 24,0),\n",
    " (24, -24,0),\n",
    " (-24, -24,0),\n",
    " (-24,24, 0)], dtype=float)\n",
    "\n",
    "keypoints, anchors = utils.get_points_from_CAD()\n",
    "anchors[:,2] +=1\n",
    "keypoints = np.hstack((keypoints,np.ones((keypoints.shape[0],1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "817eef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_pnp(obj_points, imagePoints,mtx, dist,reprojectionError ):\n",
    "    success, rvec, tvec,inliers  = cv2.solvePnPRansac(obj_points, np.array([imagePoints]), mtx, dist,reprojectionError = reprojectionError)\n",
    "        \n",
    "    if not success:\n",
    "        print('not success in PnP')\n",
    "        return\n",
    "    return tvec, rvec,inliers\n",
    "\n",
    "\n",
    "def print_error_rotation(tf_error):\n",
    "    vec = R.from_matrix(tf_error[:3,:3]).as_rotvec() \n",
    "    print(\"vector in marker\", vec/np.linalg.norm(vec))\n",
    "    print(\"angles, deg\", np.linalg.norm(vec)*57)\n",
    "\n",
    "def calculate_corrected_kts(tf_error,keypoints):\n",
    "    keypoints3d_homog = np.hstack((\n",
    "        keypoints,\n",
    "        np.ones((keypoints.shape[0],1))))\n",
    "\n",
    "    keypoints_corrected = (tf_error @ keypoints3d_homog.T).T\n",
    "    return keypoints_corrected\n",
    "\n",
    "def get_marker_pose(img_with_marker):\n",
    "    res = utils.detect_apriltag(img_with_marker, camera_params)\n",
    "    if res is None:\n",
    "        return None,None\n",
    "    corners_2d = res[0].corners\n",
    "    center_2d = res[0].center\n",
    "\n",
    "    marker_pts_2d = np.vstack((center_2d, corners_2d))\n",
    "\n",
    "    tvec_m,rvec_m,inliers_m = solve_pnp(corners_3D,marker_pts_2d,mtx, dist, 0.5)\n",
    "    \n",
    "    return tvec_m,rvec_m\n",
    "\n",
    "def get_socket_points(img, points_array, tvec, rvec, \n",
    "                      show=True):\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img)\n",
    "    img_points = None\n",
    "    img_points, _ = cv2.projectPoints(points_array, rvec, tvec, mtx, dist)\n",
    "    img_points = img_points.reshape(-1,2)\n",
    "\n",
    "    if show:\n",
    "        for p in img_points.reshape(-1,2):\n",
    "            kp = int(p[0]), int(p[1])\n",
    "            cv2.circle(img, kp, 2, (0, 0, 255), -1)\n",
    "        cv2.imshow(\"Image\", img)\n",
    "        cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return img_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f26b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_correction(img_with_marker, anchor_gt_2D):\n",
    "    def apply_correction():\n",
    "        result = tf_s_in_c.copy()\n",
    "        z_from = tf_s_in_c[:3,2]\n",
    "        z_to = tf_m_in_cam[:3,2]\n",
    "        angle = np.arccos(z_from@z_to)\n",
    "        rot_ax = np.cross(z_from,z_to)\n",
    "\n",
    "        rot_vec = rot_ax /np.linalg.norm(rot_ax) * angle\n",
    "        rot_mtx = R.from_rotvec(rot_vec).as_matrix()\n",
    "        # print(rot_mtx @ z_from -z_to )\n",
    "\n",
    "        result[:3,:3]  = rot_mtx @ tf_s_in_c[:3,:3]\n",
    "        # correction for OZ\n",
    "        d_cam = - (tf_s_in_c[:3,3] - tf_m_in_cam[:3,3])\n",
    "        z_proj = (d_cam) @ z_to\n",
    "        corr_z = np.eye(4)\n",
    "        corr_z[2,3] = z_proj\n",
    "\n",
    "        return  result @ corr_z\n",
    "\n",
    "    res = utils.detect_apriltag(img_with_marker, camera_params)\n",
    "\n",
    "    corners_2d = res[0].corners\n",
    "    center_2d = res[0].center\n",
    "\n",
    "    marker_pts_2d = np.vstack((center_2d, corners_2d))\n",
    "    tvec_m,rvec_m,inliers_m = solve_pnp(corners_3D,marker_pts_2d,mtx, dist, 0.5)\n",
    "    # print(\"inliers_m\\n\",inliers_m.T)\n",
    "\n",
    "    tf_m_in_cam = np.eye(4)\n",
    "    tf_m_in_cam[:3,:3] = R.from_rotvec(rvec_m.flatten()).as_matrix()\n",
    "    tf_m_in_cam[:3,3] = tvec_m.flatten()\n",
    "\n",
    "    tvec_gt,rvec_gt,inliers_gt = solve_pnp(anchors,anchor_gt_2D,mtx, dist,1.0)\n",
    "    # print(\"inliers_gt\\n\",inliers_gt.T)\n",
    "\n",
    "    tf_s_in_c = np.eye(4)\n",
    "    tf_s_in_c[:3,:3] = R.from_rotvec(rvec_gt.flatten()).as_matrix()\n",
    "    tf_s_in_c[:3,3] = tvec_gt.flatten()\n",
    "    tf_s_in_c_corrected = apply_correction()\n",
    "    tf_err_in_m = np.linalg.inv(tf_m_in_cam) @ tf_s_in_c_corrected\n",
    "    \n",
    "    return tf_err_in_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a539b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c9a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_marker = cv2.imread(img_with_marker_name)\n",
    "\n",
    "tvec_m,rvec_m = get_marker_pose(img_with_marker)\n",
    "\n",
    "img_without_marker = cv2.imread(img_without_marker_name)\n",
    "get_socket_points(img_without_marker, corr_kpts[:,:3], tvec_m,rvec_m)\n",
    "get_socket_points(img_without_marker, keypoints, tvec_m,rvec_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3709b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaging the corrections\n",
    "\n",
    "anchors_list = [\n",
    "    [[699, 421],[682, 397],[717, 397],[665, 421],[735, 421],[682, 451],[717, 451]],\n",
    "    [[608, 418],[594, 398],[623, 398],[ 578, 418],[368, 418],[593, 444],[623, 444]],\n",
    "    [[610, 417],[597, 399],[623, 399],[584, 417],[636, 417],[597,439],[623, 439]]\n",
    "]\n",
    "pics_list = [335, 559, 784]\n",
    "\n",
    "kpts_list = []\n",
    "for i in range(3):\n",
    "    img_with_marker_name = \"data_for_corr_new/\" + str(pics_list[i]) + ' (2).jpg'\n",
    "    img_without_marker_name = \"data_for_corr_new/\" + str(pics_list[i]) + '.jpg'\n",
    "    anchor_gt_2D = np.array(anchors_list[i], dtype = float)\n",
    "    img_with_marker = cv2.imread(img_with_marker_name)\n",
    "    img_without_marker = cv2.imread(img_without_marker_name)\n",
    "    \n",
    "    tf_err_in_m = solve_correction(img_with_marker, anchor_gt_2D)\n",
    "    corr_kpts = calculate_corrected_kts(tf_err_in_m,keypoints)\n",
    "    kpts_list.append(corr_kpts)\n",
    "\n",
    "kpts_list = np.array(kpts_list)\n",
    "kpts_list.var\n",
    "corr_kpts_mean = np.mean(kpts_list, axis = 0, dtype=np.float32)\n",
    "corr_kpts_new = np.array(corr_kpts_mean[:,:3],dtype=float)\n",
    "for i in range(3):\n",
    "    img_with_marker_name = \"data_for_corr_new/\" + str(pics_list[i]) + ' (2).jpg'\n",
    "    img_without_marker_name = \"data_for_corr_new/\" + str(pics_list[i]) + '.jpg'\n",
    "    img_with_marker = cv2.imread(img_with_marker_name)\n",
    "\n",
    "    tvec_m,rvec_m = get_marker_pose(img_with_marker)\n",
    "    \n",
    "    img_without_marker = cv2.imread(img_without_marker_name)\n",
    "    get_socket_points(img_without_marker,corr_kpts_new , tvec_m,rvec_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "177b5e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# data[0] = [[1,2],[1,4]]\n",
    "# data[1] = [[1,2],[1,4]]\n",
    "\n",
    "photos_to_ignore = [i for i in range(18,27)]\n",
    "print(33 in photos_to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ad0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "photos_to_ignore = [i for i in range(18,27)]\n",
    "processed_data = 0\n",
    "for i in range(900):\n",
    "    if i in photos_to_ignore:\n",
    "        continue\n",
    "    img_with_marker_name = \"close_photos_marker/\" + str(i) + '.jpg'\n",
    "    img_without_marker_name = \"close_photos_no_marker_normal/\" + str(i) + '.jpg'\n",
    "    img_with_marker = cv2.imread(img_with_marker_name)\n",
    "\n",
    "    tvec_m,rvec_m = get_marker_pose(img_with_marker)\n",
    "    if tvec_m is None:\n",
    "        continue\n",
    "    img_without_marker = cv2.imread(img_without_marker_name)\n",
    "    data[i] = get_socket_points(img_without_marker,corr_kpts_new , tvec_m,rvec_m, show=False).tolist()\n",
    "    \n",
    "    processed_data += 1\n",
    "    \n",
    "with open(\"ground_truth_keypoints.json\", \"w\") as write_file:\n",
    "    json.dump(data, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41fbad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_new = (tf_s_in_c @ anchor_kpts.T).T\n",
    "print(keypoints_new)\n",
    "print(keypoints.shape)\n",
    "keypoints = np.hstack((\n",
    "    keypoints,\n",
    "    np.zeros((keypoints.shape[0],1)),\n",
    "    np.ones((keypoints.shape[0],1))))\n",
    "\n",
    "\n",
    "keypoints_corrected = (tf_err_in_m @ keypoints.T).T\n",
    "\n",
    "print(keypoints_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old data for correction\n",
    "anchors_list = [\n",
    "    [[654, 358], [630,325],[680,324],[606,359],[703,358],[631,399],[679,399]],\n",
    "    [[652, 355],[630, 326],[673, 325],[609,356],[695, 356],[631, 393],[674, 393]],\n",
    "    [[648, 355],[630, 329],[670,328],[611, 355],[688, 355],[630,389],[669, 389]],\n",
    "    [[648,355],[630,331],[666, 331],[613, 355],[684,355],[630,386],[666, 386]],\n",
    "    [[647, 355],[630,332],[663, 332],[614, 355],[679,355],[630,383],[663,383]]\n",
    "]\n",
    "pics_list = [44, 108, 172,236,300]\n",
    "img_with_marker_name = \"data_for_correction/\" + str(pics_list[i]) + ' (2).jpg'\n",
    "img_without_marker_name = \"data_for_correction/\" + str(pics_list[i]) + '.jpg'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('CameraCalibrationOptimize')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c3cb1b0a8cb3060a10896d3abefa7af7f3d40811c3ca0232af182ed56385980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
