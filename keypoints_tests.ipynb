{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600a4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dt_apriltags as apriltag\n",
    "import cv2\n",
    "import annotation_utils as utils\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import urx\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "dist = np.array([[-0.04797802,  0.04744357,  0.00017416,  0.00067967, -0.00408397]])\n",
    "# detector = apriltag.Detector(families=\"tagStandard52h13\")\n",
    "mtx = np.array([[633.09029639, 0., 629.06462963], [0., 638.7544391, 362.74013262], [0., 0., 1.]])\n",
    "\n",
    "camera_params = [635.0, 635.0, 629.0646296262861, 362.7401326185789]\n",
    "corners_3D = np.array(\n",
    "[(0, 0,0),\n",
    " (24, 24,0),\n",
    " (24, -24,0),\n",
    " (-24, -24,0),\n",
    " (-24,24, 0)], dtype=float)\n",
    "\n",
    "keypoints, anchors = utils.get_points_from_CAD()\n",
    "anchors[:,2] +=1\n",
    "keypoints = np.hstack((keypoints,np.ones((keypoints.shape[0],1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "817eef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_pnp(obj_points, imagePoints,mtx, dist,reprojectionError ):\n",
    "    success, rvec, tvec,inliers  = cv2.solvePnPRansac(obj_points, np.array([imagePoints]), mtx, dist,reprojectionError = reprojectionError)\n",
    "        \n",
    "    if not success:\n",
    "        print('not success in PnP')\n",
    "        return\n",
    "    return tvec, rvec,inliers\n",
    "\n",
    "def get_socket_points(img, points_array, tvec, rvec, \n",
    "                      show=True):\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img)\n",
    "    img_points = None\n",
    "    img_points, _ = cv2.projectPoints(points_array, rvec, tvec, mtx, dist)\n",
    "    img_points = img_points.reshape(-1,2)\n",
    "\n",
    "    if show:\n",
    "        for p in img_points.reshape(-1,2):\n",
    "            kp = int(p[0]), int(p[1])\n",
    "            cv2.circle(img, kp, 2, (0, 0, 255), -1)\n",
    "        cv2.imshow(\"Image\", img)\n",
    "        cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return img_points\n",
    "def print_error_rotation(tf_error):\n",
    "    vec = R.from_matrix(tf_error[:3,:3]).as_rotvec() \n",
    "    print(\"vector in marker\", vec/np.linalg.norm(vec))\n",
    "    print(\"angles, deg\", np.linalg.norm(vec)*57)\n",
    "\n",
    "def calculate_corrected_kts(tf_error,keypoints):\n",
    "    keypoints3d_homog = np.hstack((\n",
    "        keypoints,\n",
    "        np.ones((keypoints.shape[0],1))))\n",
    "\n",
    "    keypoints_corrected = (tf_error @ keypoints3d_homog.T).T\n",
    "    return keypoints_corrected\n",
    "\n",
    "def get_marker_pose(img_with_marker):\n",
    "    res = utils.detect_apriltag(img_with_marker, camera_params)\n",
    "\n",
    "    corners_2d = res[0].corners\n",
    "    center_2d = res[0].center\n",
    "\n",
    "    marker_pts_2d = np.vstack((center_2d, corners_2d))\n",
    "    tvec_m,rvec_m,inliers_m = solve_pnp(corners_3D,marker_pts_2d,mtx, dist, 0.5)\n",
    "    return tvec_m,rvec_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8f26b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector in marker [0. 0. 1.]\n",
      "angles, deg 0.6554067255108319\n"
     ]
    }
   ],
   "source": [
    "def solve_correction(img_with_marker, anchor_gt_2D):\n",
    "    def apply_correction():\n",
    "        # rotation correction\n",
    "        result = tf_s_in_c.copy()\n",
    "        z_from = tf_s_in_c[:3,2]\n",
    "        z_to = tf_m_in_cam[:3,2]\n",
    "        angle = np.arccos(z_from@z_to)\n",
    "        rot_ax = np.cross(z_from,z_to)\n",
    "\n",
    "        rot_vec = rot_ax /np.linalg.norm(rot_ax) * angle\n",
    "        rot_mtx = R.from_rotvec(rot_vec).as_matrix()\n",
    "        # print(rot_mtx @ z_from -z_to )\n",
    "\n",
    "        result[:3,:3]  = rot_mtx @ tf_s_in_c[:3,:3]\n",
    "        # correction for OZ\n",
    "        d_cam = - (tf_s_in_c[:3,3] - tf_m_in_cam[:3,3])\n",
    "        z_proj = (d_cam) @ z_to\n",
    "        corr_z = np.eye(4)\n",
    "        corr_z[2,3] = z_proj\n",
    "\n",
    "        return  result @ corr_z\n",
    "\n",
    "    res = utils.detect_apriltag(img_with_marker, camera_params)\n",
    "\n",
    "    corners_2d = res[0].corners\n",
    "    center_2d = res[0].center\n",
    "\n",
    "    marker_pts_2d = np.vstack((center_2d, corners_2d))\n",
    "    tvec_m,rvec_m,inliers_m = solve_pnp(corners_3D,marker_pts_2d,mtx, dist, 0.5)\n",
    "    # print(\"inliers_m\\n\",inliers_m.T)\n",
    "\n",
    "    tf_m_in_cam = np.eye(4)\n",
    "    tf_m_in_cam[:3,:3] = R.from_rotvec(rvec_m.flatten()).as_matrix()\n",
    "    tf_m_in_cam[:3,3] = tvec_m.flatten()\n",
    "\n",
    "    tvec_gt,rvec_gt,inliers_gt = solve_pnp(anchors,anchor_gt_2D,mtx, dist,1.0)\n",
    "    # print(\"inliers_gt\\n\",inliers_gt.T)\n",
    "\n",
    "    tf_s_in_c = np.eye(4)\n",
    "    tf_s_in_c[:3,:3] = R.from_rotvec(rvec_gt.flatten()).as_matrix()\n",
    "    tf_s_in_c[:3,3] = tvec_gt.flatten()\n",
    "    tf_s_in_c_corrected = apply_correction()\n",
    "    tf_err_in_m = np.linalg.inv(tf_m_in_cam) @ tf_s_in_c_corrected\n",
    "    \n",
    "    return tf_err_in_m\n",
    "\n",
    "img_with_marker_name = 'marker_close_new_2.jpg'\n",
    "\n",
    "img_with_marker = cv2.imread(img_with_marker_name)\n",
    "\n",
    "anchor_gt_2D = np.array(\n",
    "[[606, 323],\n",
    "       [571, 277],\n",
    "       [642, 277],\n",
    "       [536, 323],\n",
    "       [676, 322],\n",
    "       [571, 383],\n",
    "       [640, 383]], dtype=float)\n",
    "\n",
    "img_without_marker_name = 'no_marker_close_new_2.jpg'\n",
    "\n",
    "tf_err_in_m = solve_correction(img_with_marker, anchor_gt_2D)\n",
    "corr_kpts = calculate_corrected_kts(tf_err_in_m,keypoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "017c9a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[573.83945364, 165.47394412],\n",
       "       [627.4837454 , 164.90707743],\n",
       "       [482.13230318, 205.42053634],\n",
       "       [719.83236927, 202.78585672],\n",
       "       [543.61911069, 212.49271149],\n",
       "       [658.73539763, 211.19856003],\n",
       "       [480.30397203, 246.796534  ],\n",
       "       [722.63522939, 243.9694859 ],\n",
       "       [434.79009499, 308.03149051],\n",
       "       [769.37614423, 303.86724454],\n",
       "       [516.904262  , 452.12237369],\n",
       "       [691.39746624, 449.62782582],\n",
       "       [514.85086018, 461.51077558],\n",
       "       [693.69667411, 458.93197156]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_with_marker = cv2.imread(img_with_marker_name)\n",
    "\n",
    "tvec_m,rvec_m = get_marker_pose(img_with_marker)\n",
    "\n",
    "img_without_marker = cv2.imread(img_without_marker_name)\n",
    "get_socket_points(img_without_marker, corr_kpts[:,:3], tvec_m,rvec_m)\n",
    "get_socket_points(img_without_marker, keypoints, tvec_m,rvec_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3709b43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apriltag not found\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/viktor/Annotator/keypoints_tests.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/viktor/Annotator/keypoints_tests.ipynb#X56sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m img_with_marker \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(img_with_marker_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/viktor/Annotator/keypoints_tests.ipynb#X56sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m img_without_marker \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(img_without_marker_name)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/viktor/Annotator/keypoints_tests.ipynb#X56sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m tf_err_in_m \u001b[39m=\u001b[39m solve_correction(img_with_marker, anchor_gt_2D)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/viktor/Annotator/keypoints_tests.ipynb#X56sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m corr_kpts \u001b[39m=\u001b[39m calculate_corrected_kts(tf_err_in_m,keypoints)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/viktor/Annotator/keypoints_tests.ipynb#X56sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m kpts_list\u001b[39m.\u001b[39mappend(corr_kpts)\n",
      "\u001b[1;32m/home/viktor/Annotator/keypoints_tests.ipynb Cell 5\u001b[0m in \u001b[0;36msolve_correction\u001b[0;34m(img_with_marker, anchor_gt_2D)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/viktor/Annotator/keypoints_tests.ipynb#X56sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m  result \u001b[39m@\u001b[39m corr_z\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/viktor/Annotator/keypoints_tests.ipynb#X56sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m res \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdetect_apriltag(img_with_marker, camera_params)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/viktor/Annotator/keypoints_tests.ipynb#X56sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m corners_2d \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mcorners\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/viktor/Annotator/keypoints_tests.ipynb#X56sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m center_2d \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcenter\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/viktor/Annotator/keypoints_tests.ipynb#X56sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m marker_pts_2d \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack((center_2d, corners_2d))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "anchors_list = [\n",
    "    [[654, 358], [630,325],[680,324],[606,359],[703,358],[631,399],[679,399]],\n",
    "    [[652, 355],[630, 326],[673, 325],[609,356],[695, 356],[631, 393],[674, 393]],\n",
    "    [[648, 355],[630, 329],[670,328],[611, 355],[688, 355],[630,389],[669, 389]],\n",
    "    [[648,355],[630,331],[666, 331],[613, 355],[684,355],[630,386],[666, 386]],\n",
    "    [[647, 355],[630,332],[663, 332],[614, 355],[679,355],[630,383],[663,383]]\n",
    "]\n",
    "pics_list = [44, 108, 172,236,300]\n",
    "\n",
    "kpts_list = []\n",
    "for i in range(5):\n",
    "    img_with_marker_name = \"data_for_correction/\" + str(pics_list[i]) + '.jpg'\n",
    "    img_without_marker_name = \"data_for_correction/\" + str(pics_list[i]) + ' (2).jpg'\n",
    "    anchor_gt_2D = np.array(anchors_list[i])\n",
    "    img_with_marker = cv2.imread(img_with_marker_name)\n",
    "    img_without_marker = cv2.imread(img_without_marker_name)\n",
    "    \n",
    "    tf_err_in_m = solve_correction(img_with_marker, anchor_gt_2D)\n",
    "    corr_kpts = calculate_corrected_kts(tf_err_in_m,keypoints)\n",
    "    kpts_list.append(corr_kpts)\n",
    "\n",
    "kpts_list = np.array(kpts_list)\n",
    "corr_kpts_mean = np.mean(kpts_list, axis = 0)\n",
    "print(corr_kpts_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21030711",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_kpts = np.zeros((6,2), dtype=float)\n",
    "i = 0\n",
    "anchor_kpts[2*i] = [6.143, 37.51]\n",
    "anchor_kpts[2*i+1] = [-anchor_kpts[2*i][0], anchor_kpts[2*i][1]]\n",
    "i +=1\n",
    "anchor_kpts[2*i] = [33.75, 0]\n",
    "anchor_kpts[2*i+1] = [-anchor_kpts[2*i][0], anchor_kpts[2*i][1]]\n",
    "i+=1\n",
    "anchor_kpts[2*i] = [19.9, -27.273]\n",
    "anchor_kpts[2*i+1] = [-anchor_kpts[2*i][0], anchor_kpts[2*i][1]]\n",
    "\n",
    "anchor_kpts = np.hstack((anchor_kpts, np.zeros((6,1))))\n",
    "anchor_gt_kpts2D = np.array(\n",
    "[(576, 266),\n",
    " (625, 267),\n",
    " (525, 349),\n",
    " (671, 353),\n",
    " (552, 409),\n",
    " (644, 409)], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_marker_name = 'marker.jpg'\n",
    "img_without_marker_name = 'no_marker.jpg'\n",
    "img = cv2.imread(img_without_marker_name)\n",
    "utils.show_image_with_points(img,anchor_gt_kpts2D, \"bb\")\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a5dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_points = np.zeros((5,3), dtype=float)\n",
    "obj_points[0][1] = 40.0\n",
    "obj_points[1][0] = 40.0\n",
    "obj_points[1][1] = 40.0\n",
    "obj_points[2][0] = 40.0\n",
    "obj_points[4][0] = 20.0\n",
    "obj_points[4][1] = 20.0\n",
    "\n",
    "print(obj_points.shape)\n",
    "\n",
    "for r in results:\n",
    "    imagePoints = r.corners.reshape(1,4,2)\n",
    "    center = r.center.reshape(1,1,2)\n",
    "\n",
    "    imgpoints = np.concatenate((imagePoints, center), axis=1)\n",
    "    success, rvec, tvec = cv2.solvePnP(obj_points, imgpoints, mtx, dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41fbad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_new = (tf_s_in_c @ anchor_kpts.T).T\n",
    "print(keypoints_new)\n",
    "print(keypoints.shape)\n",
    "keypoints = np.hstack((\n",
    "    keypoints,\n",
    "    np.zeros((keypoints.shape[0],1)),\n",
    "    np.ones((keypoints.shape[0],1))))\n",
    "\n",
    "\n",
    "keypoints_corrected = (tf_err_in_m @ keypoints.T).T\n",
    "\n",
    "print(keypoints_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_gt_2D = np.array(\n",
    "[(623, 336),\n",
    " (610, 318),\n",
    " (636, 318),\n",
    " (597, 336),\n",
    " (649, 336),\n",
    " (610, 358),\n",
    " (636, 358)], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_points = np.zeros((5,3), dtype=float)\n",
    "obj_points[0][1] = 40.0\n",
    "obj_points[1][0] = 40.0\n",
    "obj_points[1][1] = 40.0\n",
    "obj_points[2][0] = 40.0\n",
    "obj_points[4][0] = 20.0\n",
    "obj_points[4][1] = 20.0\n",
    "\n",
    "print(obj_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9475a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_nums(img, points, show=False):\n",
    "    for i in range(len(points)):\n",
    "        point = (int(points[i][0][0]), int(points[i][0][1]))\n",
    "        cv2.putText(img, str(i), point, cv2.FONT_HERSHEY_SIMPLEX, 12, (255,0,255))\n",
    "        cv2.circle(img, point, 2, (255,0,255), -1)\n",
    "    \n",
    "    if show:\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc471a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_socket_points(img, points_array, lines_array, bbox_array, tvec, rvec, \n",
    "                      show=False, draw_l=True, draw_p=True, draw_b=True):\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img)\n",
    "#     img = increase_brightness(img, 50)\n",
    "    img_points = None\n",
    "    \n",
    "    if draw_p:\n",
    "        img_points, _ = cv2.projectPoints(points_array, rvec, tvec, mtx, dist)\n",
    "        draw_points(img, img_points)\n",
    "    if draw_l:\n",
    "        lines_points, _ = cv2.projectPoints(lines_array, rvec, tvec, mtx, dist)\n",
    "        draw_lines(img, lines_points)\n",
    "    if draw_b:\n",
    "        bbox_arr, _ = cv2.projectPoints(bbox_array, rvec, tvec, mtx, dist)\n",
    "        draw_bbox(img, bbox_arr)\n",
    "    \n",
    "    if show:\n",
    "        cv2.imshow(\"Image\", img)\n",
    "        cv2.waitKey(1)\n",
    "    return img, img_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4cae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_apriltag(img):\n",
    "    if isinstance(img, str):\n",
    "        print('reading img from file system')\n",
    "        img = cv2.imread(img)\n",
    "    if not type(img[0][0][0]) == np.uint8:\n",
    "        img = img/img.max()\n",
    "        img *= 255\n",
    "        img = img.astype(np.uint8)\n",
    "#         cv2.imshow('detect_apriltag', img)\n",
    "        cv2.waitKey(1)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    results = detector.detect(gray,\n",
    "                              estimate_tag_pose=True,\n",
    "                              camera_params=camera_params, \n",
    "                              tag_size=0.04)\n",
    "    if not results:\n",
    "        print('apriltag not found')\n",
    "        return\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f604055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_img(image, res):\n",
    "    corners = res[0].corners\n",
    "    \n",
    "    corners[:2] = np.array(sorted(corners[:2], key=lambda x: x[1]))\n",
    "    corners[2:] = np.array(sorted(corners[2:], key=lambda x: x[1]))\n",
    "\n",
    "    a = corners[:2][:, 0].mean()\n",
    "    c = corners[2:][:, 0].mean()\n",
    "    b = corners[::2][:, 1].mean()\n",
    "    d = corners[1::2][:, 1].mean()\n",
    "\n",
    "    desired_corners = np.array([[a, b], [a, d], [c, b], [c, d]], dtype=int)\n",
    "\n",
    "    tform = get_projection(desired_corners, corners)\n",
    "    image_warped = warp(image, tform)\n",
    "    return image_warped, desired_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ecb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projection(c_to, c_from):\n",
    "    tform = ProjectiveTransform()\n",
    "    tform.estimate(c_to, c_from)\n",
    "    return tform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose_left = ur10.getl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01dc535",
   "metadata": {},
   "outputs": [],
   "source": [
    "ur10.movej((-4.048973385487692, -1.1045106093036097, 1.546417236328125,\n",
    "            2.811586380004883, -0.7216728369342249, 3.1041338443756104))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b2eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose_center = ur10.getl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose_right = ur10.getl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_arr = np.array(\n",
    "    [[-132. ,   44. ,  -46. ],\n",
    "       [-132. ,   27. ,  -46. ],\n",
    "       [-143. ,   46. ,  -43. ],\n",
    "       [-143. ,   40. ,  -45. ],\n",
    "       [-142.5,   31. ,  -46. ],\n",
    "       [-142.5,   24. ,  -45. ],\n",
    "       [-149. ,   60. ,  -45. ],\n",
    "       [-149. ,   43. ,  -44. ],\n",
    "       [-149. ,   27. ,  -45. ],\n",
    "       [-149. ,   11. ,  -45. ],\n",
    "       [-156. ,   47. ,  -46. ],\n",
    "       [-156. ,   39. ,  -45. ],\n",
    "       [-156. ,   31. ,  -46. ],\n",
    "       [-156. ,   23. ,  -46. ],\n",
    "       [-162. ,   35. ,  -45. ],\n",
    "       [-171. ,   44. ,  -46. ],\n",
    "       [-171. ,   27. ,  -45. ]], dtype=np.float32)\n",
    "DEPTH = -40\n",
    "bbox = np.array([\n",
    "    [10, 128, DEPTH],\n",
    "    [59, 128, DEPTH],\n",
    "    [59, 170, DEPTH],\n",
    "    [10, 170, DEPTH]\n",
    "], dtype=float)\n",
    "bbox[:,[0, 1]] = bbox[:,[1, 0]]\n",
    "bbox[:, 0] = -bbox[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6800670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = np.array([\n",
    "    [0,0,0],\n",
    "    [100,0,0],\n",
    "    [0,100,0],\n",
    "    [0,0,100]\n",
    "], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7eb655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(img, bbox_arr, show=False):\n",
    "    print(bbox_arr)\n",
    "    color = (0,255,0)\n",
    "    cv2.line(img, \n",
    "            [int(x) for x in bbox_arr[0][0]],\n",
    "            [int(x) for x in bbox_arr[1][0]], color, 1)\n",
    "    cv2.line(img, \n",
    "            [int(x) for x in bbox_arr[1][0]], \n",
    "            [int(x) for x in bbox_arr[2][0]], color, 1)\n",
    "    cv2.line(img, \n",
    "            [int(x) for x in bbox_arr[2][0]], \n",
    "            [int(x) for x in bbox_arr[3][0]], color, 1)\n",
    "    cv2.line(img, \n",
    "            [int(x) for x in bbox_arr[3][0]], \n",
    "            [int(x) for x in bbox_arr[0][0]], color, 1)\n",
    "    \n",
    "    if show:\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img, line_arr, show=False):\n",
    "    colors = [(255,255,0), (0,255,0), (0,0,255)]\n",
    "    for i, line in enumerate(line_arr[1:]):\n",
    "        cv2.line(img, [int(x) for x in line_arr[0][0]], [int(x) for x in line[0]], colors[i-1], 2)\n",
    "    if show:\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abc450",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6c2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 2\n",
    "count = 0\n",
    "centers = []\n",
    "# ress = []\n",
    "while count < 10:\n",
    "    img = get_photo_from_realsense()\n",
    "    res = detect_apriltag(img)\n",
    "    count += 1\n",
    "    \n",
    "    if not res: \n",
    "        continue\n",
    "\n",
    "#     ress = res\n",
    "#     break\n",
    "#     centers.append(res[0].center)\n",
    "#     print(res)\n",
    "#     ress.append(res)\n",
    "    \n",
    "    draw_apriltag(img, res,show=True)\n",
    "    tvec, rvec,objpts = solve_pnp(res)\n",
    "    print(tvec)\n",
    "#     processed, _ = get_socket_points(img, points_arr, lines, bbox, tvec, rvec, \n",
    "#                                    show=True, draw_l=True, draw_p=True, draw_b=False)\n",
    "    \n",
    "    \n",
    "#     fname = f'/home/viacheslav/jupyter_notebooks/{name}_processed.jpg'\n",
    "#     cv2.imwrite(fname, img)\n",
    "#     name += 1\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb294e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[-23.50502963]\n",
    " [  8.35980833]\n",
    " [110.64977061]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e230ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = np.array(centers)\n",
    "\n",
    "print(np.var(centers,axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ef41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 1\n",
    "ress1 = []\n",
    "centers = []\n",
    "corners = []\n",
    "count = 0\n",
    "while name< 100:\n",
    "    img = get_photo_from_realsense()\n",
    "    res = detect_apriltag(img)\n",
    "#     print(res)\n",
    "    if not res: \n",
    "        continue\n",
    "    for r in res:\n",
    "        centers.append(r.center)\n",
    "        corners.append(r.corners)\n",
    "    count+=1\n",
    "#     ress.append(res)\n",
    "#     cv2.imshow(\"Image\", img)\n",
    "#     cv2.waitKey(10)\n",
    "    draw_apriltag(img, res)\n",
    "#     tvec, rvec, objpts = solve_pnp(res)\n",
    "#     processed, _ = get_socket_points(img, points_arr, lines, bbox, tvec, rvec, \n",
    "#                                    show=True, draw_l=True, draw_p=False, draw_b=False)\n",
    "    \n",
    "    \n",
    "    fname = f'/home/viacheslav/jupyter_notebooks/new_data/{name}_processed.jpg'\n",
    "#     print(fname)\n",
    "    cv2.imwrite(fname, img)\n",
    "    name += 1\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee499ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = np.array(centers)\n",
    "print(np.mean(centers,axis = 0))\n",
    "print(np.sqrt(np.var(centers,axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03165814",
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = np.array(corners)\n",
    "# i = 0\n",
    "for i in range (4):\n",
    "# print(np.mean(corners[:,i],axis = 0))\n",
    "    print(np.sqrt(np.var(corners[:,i],axis = 0)))\n",
    "# print(corners[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('CameraCalibrationOptimize')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c3cb1b0a8cb3060a10896d3abefa7af7f3d40811c3ca0232af182ed56385980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
